from datetime import datetime
import unicodedata
from plugins.Hulaquan.SaojuDataManager import SaojuDataManager
import requests
import re
import json
from plugins.AdminPlugin.BaseDataManager import BaseDataManager

"""
    æ›´æ–°æ€è·¯ï¼š
    1.æŒ‰ç…§æ˜¯å¦ä¿®æ”¹selfå°†å‡½æ•°æ•°æ®åˆ†ç±»
    """



class HulaquanDataManager(BaseDataManager):
    """
    åŠŸèƒ½ï¼š
    1.å­˜å‚¨/è°ƒå–å¡å¸æ’æœŸæ•°æ®
    2.æ ¹æ®å¡å¸æ•°æ®æœ‰æ•ˆæœŸåˆ·æ–°
    
    {
        "events":{}
        "update_time":datetime
    }
    """
    def __init__(self, file_path=None):
        #file_path = file_path or "data/Hulaquan/hulaquan_events_data.json"
        super().__init__(file_path)
        
    def _check_data(self):
        self.data.setdefault("events", {})  # ç¡®ä¿æœ‰ä¸€ä¸ªäº‹ä»¶å­—å…¸æ¥å­˜å‚¨æ•°æ®

    def fetch_and_update_data(self):
        """æ›´æ–°æ•°æ®

        Returns:
            è¿”å›(old_data, new_data)
        """
        old_data = self.data
        self._update_events_data()
        return old_data, self.data

    def search_events_data_by_recommendation_link(self, limit=12, page=0, timeMark=True, tags=None):
        # get events from recommendation API
        recommendation_url = "https://clubz.cloudsation.com/site/getevent.html?filter=recommendation&access_token="
        try:
            recommendation_url = recommendation_url + "&limit=" + str(limit) + "&page=" + str(page)
            response = requests.get(recommendation_url)
            response.raise_for_status()
            json_data = response.content.decode('utf-8-sig')
            json_data = json.loads(json_data)
            result = []
            for event in json_data["events"]:
                if not timeMark or (timeMark and event["timeMark"] > 0):
                    if not tags or (tags and any(tag in event["tags"] for tag in tags)):
                        result.append(event["basic_info"])
        except requests.RequestException as e:
            return f"Error fetching recommendation: {e}"
        return json_data["count"], result

    def _update_events_data(self, data_dict=None):
        try:
            #self.update(json.dumps(data_dict or self.get_events_dict(), ensure_ascii=False))
            data_dict = data_dict or self.get_events_dict()
            self.data["events"] = data_dict["events"]
            for eid in list(self.data["events"].keys()):
                self._update_ticket_details(eid)
            self.data["update_time"] = data_dict["update_time"]
            return self.data
        except Exception as e:
            print(f"å‘¼å•¦åœˆæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            return None

    def get_events_dict(self):
        """
        Generate a dictionary of events from the recommendation API.
        datadict: {event_id: event_info}
        event_info: {"3848": {
            "id": 3848,
            "title": "åŸåˆ›ç¯å¢ƒå¼éŸ³ä¹å‰§ã€Šæµæ˜Ÿä¹‹ç»Šã€‹æ”¹ç¼–è‡ªä¸œé‡åœ­å¾åŒåå°è¯´",
            "location": "ä¸Šæµ·å¸‚é»„æµ¦åŒºè¥¿è—å—è·¯1å·å¤§ä¸–ç•Œ4æ¥¼Eå…ï¼ˆä¸Šæµ·å¤§ä¸–ç•ŒÂ·æ˜Ÿç©ºé—´10å·Â·MOriginal Boxï¼‰",
            "start_time": "2025-05-01 19:30:00",
            "end_time": "2025-06-30 21:30:00",
            "deadline": "2025-06-30 21:30:00",
            "all_day_event": null,
            "rich_description": "<h4 style=\"text-wrap: wrap; border-bottom: 1px solid rgb(187, 187, 187); border-right: 1px solid rgb(187, 187, 187); color: rgb(51, 51, 51); font-family: é»‘ä½“; letter-spacing: 1px; line-height: 24px; background-color: rgb(238, 238, 238); font-size: 14px; padding-left: 6px; margin: 15px 0px;\">è´­ç¥¨é¡»çŸ¥</h4><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: center;\"><span style=\"color: rgb(192, 0, 0);\"><strong><span style=\"text-align: justify;\">å­¦ç”Ÿç¥¨ç›²ç›’</span></strong></span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: center;\"><span style=\"color: rgb(192, 0, 0);\"><strong><span style=\"text-align: justify;\">199å…ƒ(399~499åº§ä½éšæœº)</span></strong></span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51);\"><span style=\"text-align: justify;\">ã€è´­ç¥¨æ–¹å¼ã€‘ç‚¹å‡»æ´»åŠ¨ä¸‹æ–¹çš„å¯¹åº”çš„æ—¶é—´åœºæ¬¡å›¾æ ‡å¯æŒ‰æç¤ºè´­ç¥¨ã€‚è¯·ä¸‹è½½å‘¼å•¦åœˆAPPæ”¶åˆ°æ¼”å‡ºé€šçŸ¥å’Œæé†’ã€‚</span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51);\"><span style=\"text-align: justify;\"><span style=\"color: rgb(192, 0, 0); font-family: å¾®è½¯é›…é»‘, å®‹ä½“; font-size: 13px; letter-spacing: 1px; text-align: justify; text-wrap: wrap;\">ç¥¨å“ä¸ºæœ‰ä»·è¯åˆ¸ï¼Œéæ™®é€šå•†å“ï¼Œå…¶åæ‰¿è½½çš„æ–‡åŒ–æœåŠ¡å…·æœ‰æ—¶æ•ˆæ€§ï¼Œç¨€ç¼ºæ€§ç­‰ç‰¹å¾ï¼Œä¸æ”¯æŒé€€æ¢ã€‚è´­ç¥¨æ—¶è¯·å‹¿ä»”ç»†æ ¸å¯¹ç›¸å…³ä¿¡æ¯å¹¶è°¨æ…ä¸‹å•ã€‚</span></span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: justify;\">ã€å–ç¥¨è§„åˆ™ã€‘<strong><span style=\"color: rgb(118, 146, 60);\">å­¦ç”Ÿç¥¨</span></strong>: æ¼”å‡ºå½“å¤©æå‰ä¸€å°æ—¶ï¼Œå‡­å­¦ç”Ÿè¯è‡³ä¸Šæµ·å¸‚é»„æµ¦åŒºè¥¿è—å—è·¯1å·å¤§ä¸–ç•Œ4æ¥¼Eå…ï¼ˆä¸Šæµ·å¤§ä¸–ç•ŒÂ·æ˜Ÿç©ºé—´10å·Â·MOriginal Boxï¼‰å–ç¥¨å¤„å®åå–ç¥¨åŠå…¥åœºï¼Œäººè¯ç¥¨ä¸€è‡´æ–¹å¯å…¥åœºã€‚ã€‚<strong>å­¦ç”Ÿç¥¨ç¦æ­¢è½¬è®©ï¼Œä»…é™è´­ç¥¨æœ¬äººä½¿ç”¨ã€‚</strong></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: justify;\">ã€å’¨è¯¢ç”µè¯ã€‘4008781318, å°å‘¼å•¦å¾®ä¿¡:hulacampus<a href=\"https://weibo.com/7741472507\" target=\"_self\"><strong style=\"text-align: center; color: rgb(192, 0, 0);\"><span style=\"text-align: justify;\"><img src=\"http://lift.cloudsation.com/meetup/detail/1861640866230308864.jpg\" title=\"\" alt=\"å¾®ä¿¡å›¾ç‰‡_20241127131538.jpg\" width=\"70\" height=\"54\" style=\"width: 70px; height: 54px; float: right;\"/></span></strong></a><span style=\"font-size: 13px;\"><br/></span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: justify;\"><span style=\"font-size: 13px;\">ã€å¼‚å¸¸è®¢è´­è¯´æ˜ã€‘</span><span style=\"font-size: 13px;\"></span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: justify;\"><span style=\"font-size: 13px;\">å¯¹äºå¼‚å¸¸è®¢è´­è¡Œä¸ºï¼Œå‘¼å•¦åœˆæœ‰æƒåœ¨è®¢å•æˆç«‹æˆ–è€…ç”Ÿæ•ˆä¹‹åå–æ¶ˆç›¸åº”è®¢å•ã€‚å¼‚å¸¸è®¢è´­è¡Œä¸ºåŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹æƒ…å½¢ï¼š ï¼ˆ1ï¼‰é€šè¿‡åŒä¸€IDè®¢è´­è¶…å‡ºé™è´­å¼ æ•°çš„è®¢å•ï¼› ï¼ˆ2ï¼‰ç»åˆç†åˆ¤æ–­è®¤ä¸ºéçœŸå®æ¶ˆè´¹è€…çš„ä¸‹å•è¡Œä¸ºï¼ŒåŒ…æ‹¬ä½†ä¸é™äºé€šè¿‡æ‰¹é‡ç›¸åŒæˆ–è™šæ„çš„æ”¯ä»˜è´¦å·ã€æ”¶è´§åœ°å€ï¼ˆåŒ…æ‹¬ä¸‹å•æ—¶å¡«å†™åŠæœ€ç»ˆå®é™…æ”¶è´§åœ°å€ï¼‰ã€æ”¶ä»¶äººã€ç”µè¯å·ç è®¢è´­è¶…å‡ºé™è´­å¼ æ•°çš„è®¢å•</span></p><p style=\"text-wrap: wrap; font-family: å¾®è½¯é›…é»‘, å®‹ä½“; letter-spacing: 1px; line-height: 28px; font-size: 14px; color: rgb(51, 51, 51); text-align: justify;\"><span style=\"font-size: 13px;\"><strong style=\"color: rgb(74, 74, 74); font-family: å¾®è½¯é›…é»‘;\"></strong><strong style=\"color: rgb(74, 74, 74); font-family: å¾®è½¯é›…é»‘;\">å…¥åœºæ¸©é¦¨æç¤º</strong><br/>å…¥åœºæ—¶ï¼Œè¯·å¬ä»ç°åœºå·¥ä½œäººå‘˜çš„å¼•å¯¼æŒ‡ç¤ºï¼Œä¿æŒä¸€ç±³ä»¥ä¸Šé—´éš”æœ‰åºå…¥åœºï¼Œåœºå†…ä¸¥ç¦é¥®é£Ÿï¼Œæ„Ÿè°¢æ‚¨çš„æ”¯æŒä¸é…åˆï¼Œç¥æ‚¨è§‚æ¼”æ„‰å¿«ï¼</span><span style=\"font-size: 13px;\">å› ä¸ªäººåŸå› å¯¼è‡´æ— æ³•å…¥åœºï¼Œå°†ä¸åšé€€æ¢ç¥¨å¤„ç†ï¼Œæ•¬è¯·è°…è§£ï¼</span></p><h4 style=\"text-wrap: wrap; border-bottom: 1px solid rgb(187, 187, 187); border-right: 1px solid rgb(187, 187, 187); color: rgb(51, 51, 51); font-family: é»‘ä½“; letter-spacing: 1px; line-height: 24px; background-color: rgb(238, 238, 238); font-size: 14px; padding-left: 6px; margin: 15px 0px;\">æ¼”å‡ºä»‹ç»</h4><p style=\"text-align: center;\"><img src=\"http://lift.cloudsation.com/meetup/detail/1902573448199278592.jpg\" title=\"\" alt=\"1.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573478154997760.jpg\" title=\"\" alt=\"2.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573508114911232.jpg\" title=\"\" alt=\"3.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573537902858240.jpg\" title=\"\" alt=\"4.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573568303173632.jpg\" title=\"\" alt=\"5.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573597822685184.jpg\" title=\"\" alt=\"6.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573624242606080.jpg\" title=\"\" alt=\"7.jpg\" style=\"width: 100%;\"/><img src=\"http://lift.cloudsation.com/meetup/detail/1902573657746706432.jpg\" title=\"\" alt=\"8.jpg\" style=\"width: 100%;\"/></p>",
            "description": "",
            "description_url": null,
            "organizer": 81460,
            "status": "processing",
            "directory": null,
            "min_people": null,
            "max_people": 1000,
            "type": "public",
            "create_time": "2025-03-17 14:28:16",
            "contact": "4008781318",
            "location_id": null,
            "update_time": "2025-05-14 15:26:22",
            "phone_required": false,
            "verify_required": false,
            "verify_detail": null,
            "sponsor": null,
            "sponsor_url": null,
            "view_count": 20199,
            "show_qr_code": 1}
        Returns:
            _type_: _description_
        """
        data = self.search_all_events()
        data_dic = {"events":{}, "update_time":""}
        keys_to_extract = ["id", "title", "location", "start_time", "end_time", "update_time", "deadline", "create_time"]
        for event in data:
            event_id = str(event["id"])
            if event_id not in data_dic["events"]:
                data_dic["events"][event_id] = {key: event.get(key, None) for key in keys_to_extract}
        data_dic["update_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return data_dic

    def search_all_events(self):
        #count = self.get_recommendation(1,0,False)[0]  # Test the connection and the count
        #print(f"Total recommendations available: {count}")
        data = []
        data += self.search_events_data_by_recommendation_link(100, 0, True)[1]
        return data
    
    def return_events_data(self):
        if not self.data.get("events", None):
            self._update_events_data()
            print("å‘¼å•¦åœˆæ•°æ®å·²æ›´æ–°")
        return self.data["events"]

    def search_eventID_by_name(self, event_name):
        data = self.return_events_data()
        result = []
        for eid, event in data.items():
            title = event["title"]
            if re.search(event_name, title, re.IGNORECASE):
                result.append([eid, title])
        return result
        
    def search_event_by_id(self, event_id):
        # æ ¹æ®eidæŸ¥æ‰¾äº‹ä»¶è¯¦ç»†ä¿¡æ¯ ä¸»è¦ç”¨æ¥è·å–ä½™ç¥¨ä¿¡æ¯
        event_url = f"https://clubz.cloudsation.com/event/getEventDetails.html?id={event_id}"
        try:
            response = requests.get(event_url)
            response.raise_for_status()
            json_data = response.content.decode('utf-8-sig')
            json_data = json.loads(json_data)
            return json_data
        except requests.RequestException as e:
            print(f"Error fetching event details: {e}")
            return None

    def search_ticket_details(self, event_id):
        json_data = self.search_event_by_id(event_id)
        keys_to_extract = ["id","event_id","title", "start_time", "end_time","status","create_time","ticket_price","total_ticket", "left_ticket_count", "left_days"]
        json_data: list = json_data["ticket_details"]
        for i in range(len(json_data)):
            json_data[i] = {key: json_data[i].get(key, None) for key in keys_to_extract}
        return json_data
        
    def get_ticket_details(self, event_id):
        if not self.data["events"][event_id].get("ticket_details", None):
            self._update_ticket_details(event_id)
        return self.data["events"][event_id]
    
    def _update_ticket_details(self, event_id):
        self.data["events"][event_id]["ticket_details"] = self.search_ticket_details(event_id)
        
    def output_data_info(self):
        old_data = self.return_events_data()
        for eid, event in old_data.items():
            print(eid, event["title"], event["end_time"], event["update_time"])
        
    # ------------------------------------------ #


    def get_max_ticket_content_length(self, tickets):
        max_len = 0
        for ticket in tickets:
            s = f"{ticket['title']} ä½™ç¥¨{ticket['left_ticket_count']}/{ticket['total_ticket']}"
            max_len = max(max_len, get_display_width(s))
        return max_len

    # -------------------Query------------------------------ #         
    # ---------------------Announcement--------------------- #

    def compare_to_database(self):
        # å°†æ–°çˆ¬çš„æ•°æ®ä¸æ—§æ•°æ®è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºéœ€è¦æ›´æ–°çš„æ•°æ®
        """
        __dump: bool, æ˜¯å¦å°†æ–°æ•°æ®å†™å…¥æ–‡ä»¶
        Returns:
            update_data: list, åŒ…å«éœ€è¦æ›´æ–°çš„äº‹ä»¶æ•°æ®
            None: å¦‚æœæ²¡æœ‰éœ€è¦æ›´æ–°çš„æ•°æ®
        """
        
        is_updated = False
        old_data_all, new_data_all = self.fetch_and_update_data()
        new_data = new_data_all["events"]
        old_data = old_data_all["events"]
        messages = []
        for eid, event in new_data.items():
            message = []
            old_event = old_data[eid]
            if eid not in old_data.keys():
                t = [f"âœ¨" if ticket['left_ticket_count'] > 0 else "âŒ" + f"{ticket['title']} ä½™ç¥¨{ticket['left_ticket_count']}/{ticket['total_ticket']}" for ticket in event.get("ticket_details", [])]
                message.append("ğŸŸ¢æ–°å¼€ç¥¨åœºæ¬¡ï¼š" + "\n ".join(t))
            elif comp := self.compare_tickets(old_event.get("ticket_details", None), new_data[eid].get("ticket_details", None)):
                new_message = []
                return_message = []
                add_message = []
                for ticket in comp:
                    flag = ticket['update_status']
                    t = f"âœ¨" if ticket['left_ticket_count'] > 0 else "âŒ" + f"{ticket['title']} ä½™ç¥¨{ticket['left_ticket_count']}/{ticket['total_ticket']}"
                    if flag == 'new':
                        new_message.append(t)
                    elif flag == 'return':
                        return_message.append(t)
                    elif flag == 'add':
                        add_message.append(t)
                if new_message:
                    message.append(f"ğŸŸ¢æ–°å¼€ç¥¨åœºæ¬¡ï¼š{'\n '.join(new_message)}")
                if return_message:
                    message.append(f"ğŸŸ¢å›æµï¼ˆï¼Ÿï¼‰åœºæ¬¡ï¼š{'\n '.join(return_message)}")
                if add_message:
                    message.append(f"ğŸŸ¢è¡¥ç¥¨åœºæ¬¡ï¼š{'\n '.join(add_message)}")
            else:
                continue
            messages.append((
                f"å‰§å: {event['title']}\n"
                f"æ´»åŠ¨ç»“æŸæ—¶é—´: {event['end_time']}\n"
                f"æ›´æ–°æ—¶é—´: {event['update_time']}\n"
            ) + "\n".join(message))
            is_updated = True
        return is_updated, messages

    def compare_tickets(self, old_data, new_data):
        """
{
  "id": 31777,
  "event_id": 3863,
  "title": "ã€Šæµ·é›¾ã€‹07-19 20:00ï¿¥199ï¼ˆåŸä»·ï¿¥299) å­¦ç”Ÿç¥¨",
  "start_time": "2025-07-19 20:00:00",
  "end_time": "2025-07-19 21:00:00",
  "status": "active", /expired
  "create_time": "2025-06-11 11:06:13",
  "ticket_price": 199,
  "max_ticket": 1,
  "total_ticket": 14,
  "left_ticket_count": 0,
  "left_days": 25,
}
        """
        if not old_data or not new_data:
            return new_data
        old_data_dict = {item['id']: item for item in old_data}
        update_data = []

        # éå† new_data å¹¶æ ¹æ®æ¡ä»¶è¿›è¡Œæ›´æ–°
        for new_item in new_data:
            new_id = new_item['id']
            new_left_ticket_counts = new_item['left_ticket_counts']
            new_total_ticket = new_item['total_ticket']

            if new_id not in old_data_dict:
                # å¦‚æœ new_data ä¸­å­˜åœ¨æ–°çš„ idï¼Œåˆ™æ ‡è®°ä¸º "new"
                new_item['update_status'] = 'new'
                update_data.append(new_item)
            else:
                # è·å– old_data ä¸­å¯¹åº” id çš„æ—§æ•°æ®
                old_item = old_data_dict[new_id]
                old_left_ticket_counts = old_item['left_ticket_counts']
                old_total_ticket = old_item['total_ticket']
                if new_total_ticket > old_total_ticket:
                    # å¦‚æœ total_ticket å¢åŠ äº†ï¼Œåˆ™æ ‡è®°ä¸º "add"
                    new_item['update_status'] = 'add'
                    update_data.append(new_item)
                elif new_left_ticket_counts > old_left_ticket_counts:
                    # å¦‚æœ left_ticket_counts å¢åŠ äº†ï¼Œåˆ™æ ‡è®°ä¸º "return"
                    new_item['update_status'] = 'return'
                    update_data.append(new_item)
                else:
                    new_item['update_status'] = None
        return update_data
        
        
    def on_message_tickets_query(self, eName, saoju, ignore_sold_out=False, show_cast=True):
        query_time = datetime.now()
        result = self.search_eventID_by_name(eName)
        if len(result) > 1:
            queue = [f"{i}. {event[1]}" for i, event in enumerate(result, start=1)]
            return f"æ‰¾åˆ°å¤šä¸ªåŒ¹é…çš„å‰§åï¼Œè¯·é‡æ–°ä»¥å”¯ä¸€çš„å…³é”®è¯æŸ¥è¯¢ï¼š\n" + "\n".join(queue)
        elif len(result) == 1:
            eid = result[0][0]
            return self.generate_tickets_query_message(eid, query_time, eName, saoju, show_cast=show_cast, ignore_sold_out=ignore_sold_out)
        else:
            return "æœªæ‰¾åˆ°è¯¥å‰§ç›®ã€‚"

    def generate_tickets_query_message(self, eid, query_time, eName, saoju:SaojuDataManager, show_cast=True, ignore_sold_out=False):
        event_data = self.data[eid]
        if event_data:
            title = event_data.get("title", "æœªçŸ¥å‰§å")
            tickets_details = event_data.get("ticket_details", [])
            remaining_tickets = []
            for ticket in tickets_details:
                if ticket["status"] == "active":
                    if ticket["left_ticket_count"] > (0 if ignore_sold_out else -1):
                        remaining_tickets.append(ticket)
            max_ticket_info_count = self.get_max_ticket_content_length(remaining_tickets)
            query_time_str = query_time.strftime("%Y-%m-%d %H:%M:%S")
            url = f"https://clubz.cloudsation.com/event/{eid}.html"
            message = (
                f"å‰§å: {title}\n"
                f"æ•°æ®æ›´æ–°æ—¶é—´: {query_time_str}\n"
                f"è´­ç¥¨é“¾æ¥ï¼š{url}\n"
                "å‰©ä½™ç¥¨åŠ¡ä¿¡æ¯:\n"
                + "\n".join([("âœ¨" if ticket['left_ticket_count'] > 0 else "âŒ") 
                                + ljust_for_chinese(f"{ticket['title']} ä½™ç¥¨{ticket['left_ticket_count']}/{ticket['total_ticket']}", max_ticket_info_count)
                                + ((" " + (" ".join(saoju.search_casts_by_date_and_name(eName, 
                                                                                ticket['start_time'], 
                                                                                city=extract_city(event_data.get("location", ""))
                                                                                )
                                                )
                                        )
                                ) if show_cast else "")
                                for ticket in remaining_tickets
                                ])
                if remaining_tickets else "æš‚æ— å‰©ä½™ç¥¨åŠ¡ä¿¡æ¯ã€‚"
                                )
            now_time = datetime.now()
            delta_time = now_time - query_time
            message += f"\nâŒšè€—æ—¶: {delta_time.total_seconds():.2f}ç§’âŒš"
            return message
        else:
            return "æœªæ‰¾åˆ°è¯¥å‰§ç›®çš„è¯¦ç»†ä¿¡æ¯ã€‚"
        
    def message_update_data(self):
        # Return: (is_updated: bool, messages: [list:Str])
        query_time = datetime.now()
        query_time_str = query_time.strftime("%Y-%m-%d %H:%M:%S")
        is_updated, msg = self.compare_to_database()
        if not is_updated:
            return (False, [f"æ— æ›´æ–°æ•°æ®ã€‚\næŸ¥è¯¢æ—¶é—´ï¼š{query_time_str}\nä¸Šæ¬¡æ•°æ®æ›´æ–°æ—¶é—´ï¼š{update_data}",])
        messages = [f"æ£€æµ‹åˆ°å‘¼å•¦åœˆæœ‰{len(msg)}æ¡æ•°æ®æ›´æ–°\næŸ¥è¯¢æ—¶é—´ï¼š{query_time_str}"]
        messages.extend(msg)
        return (True, messages)
        

    # ---------------------é™æ€å‡½æ•°--------------------- #
def get_display_width(s):
    width = 0
    for char in s:
        # åˆ¤æ–­å­—ç¬¦æ˜¯å¦æ˜¯å…¨å®½å­—ç¬¦ï¼ˆé€šå¸¸æ˜¯ä¸­æ–‡ç­‰ï¼‰
        if unicodedata.east_asian_width(char) in ['F', 'W']:  # 'F' = Fullwidth, 'W' = Wide
            width += 3  # å…¨å®½å­—ç¬¦å ç”¨2ä¸ªä½ç½®
        else:
            width += 1  # åŠå®½å­—ç¬¦å ç”¨1ä¸ªä½ç½®
    return width

def ljust_for_chinese(s, width, fillchar=' '):
    current_width = get_display_width(s)
    if current_width >= width:
        return s
    fill_width = width - current_width
    result = s + fillchar * fill_width
    return result

def standardize_datetime(dateAndTime):
    current_year = datetime.now().year
    if len(dateAndTime.split("-")[0]) != 4:
        dateAndTime = str(current_year) + "-" + dateAndTime
    try:
        dt = datetime.strptime(dateAndTime, "%Y-%m-%d %H:%M:%S")
    except ValueError:
        dt = datetime.strptime(dateAndTime, "%Y-%m-%d %H:%M")
    return dt.strftime("%Y-%m-%d %H:%M")

def extract_city(address):
    city_pattern_1 = r'([^\s]{2})å¸‚'
    city_pattern_2 = r'([^\s]{4,})åŒº'
    city_pattern_3 = r'([^\s]+çœ)'
    match = re.search(city_pattern_1, address)
    if match:
        return match.group(1)
    match = re.search(city_pattern_2, address)
    if match:
        return None

    match = re.search(city_pattern_3, address)
    if match:
        return match.group(1)[:-1]
    return None